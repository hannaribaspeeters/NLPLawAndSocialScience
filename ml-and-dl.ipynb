{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d21e1ead",
      "metadata": {
        "id": "d21e1ead"
      },
      "source": [
        "# HW04: ML and DL"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "680d1f0b",
      "metadata": {
        "id": "680d1f0b"
      },
      "source": [
        "Remember that these homework work as a completion grade. **You can skip one section without losing credit.**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9bf38c8",
      "metadata": {
        "id": "c9bf38c8"
      },
      "source": [
        "## Load and Pre-process Text\n",
        "We do sentiment analysis on the [Movie Review Data](https://www.cs.cornell.edu/people/pabo/movie-review-data/). If you would like to know more about the data, have a look at [the paper](https://www.cs.cornell.edu/home/llee/papers/pang-lee-stars.pdf) (but no need to do so)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "21439804",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21439804",
        "outputId": "031900d3-fc43-48ae-b87c-3a672aef42e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-22 13:40:19--  https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  22.1MB/s    in 4.8s    \n",
            "\n",
            "2023-03-22 13:40:24 (16.6 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n",
            "--2023-03-22 13:40:42--  https://www.cs.cornell.edu/people/pabo/movie-review-data/scale_data.tar.gz\n",
            "Resolving www.cs.cornell.edu (www.cs.cornell.edu)... 132.236.207.36\n",
            "Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4029756 (3.8M) [application/x-gzip]\n",
            "Saving to: ‘scale_data.tar.gz’\n",
            "\n",
            "scale_data.tar.gz   100%[===================>]   3.84M  17.9MB/s    in 0.2s    \n",
            "\n",
            "2023-03-22 13:40:42 (17.9 MB/s) - ‘scale_data.tar.gz’ saved [4029756/4029756]\n",
            "\n",
            "--2023-03-22 13:40:42--  https://www.cs.cornell.edu/people/pabo/movie-review-data/scale_whole_review.tar.gz\n",
            "Resolving www.cs.cornell.edu (www.cs.cornell.edu)... 132.236.207.36\n",
            "Connecting to www.cs.cornell.edu (www.cs.cornell.edu)|132.236.207.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8853204 (8.4M) [application/x-gzip]\n",
            "Saving to: ‘scale_whole_review.tar.gz’\n",
            "\n",
            "scale_whole_review. 100%[===================>]   8.44M  32.0MB/s    in 0.3s    \n",
            "\n",
            "2023-03-22 13:40:43 (32.0 MB/s) - ‘scale_whole_review.tar.gz’ saved [8853204/8853204]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# In this tutorial, we do sentiment analysis\n",
        "# download the data\n",
        "!wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar xf aclImdb_v1.tar.gz\n",
        "\n",
        "!wget https://www.cs.cornell.edu/people/pabo/movie-review-data/scale_data.tar.gz\n",
        "!wget https://www.cs.cornell.edu/people/pabo/movie-review-data/scale_whole_review.tar.gz\n",
        " \n",
        "!tar xf scale_data.tar.gz \n",
        "!tar xf scale_whole_review.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d685ef2e",
      "metadata": {
        "id": "d685ef2e"
      },
      "source": [
        "First, we have to load the data for which we provide the function below. Note how we also preprocess the text using gensim's simple_preprocess() function and how we already split the data into a train and test split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a18a238d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a18a238d",
        "outputId": "6200786f-6336-4d63-ce5a-20632a41f3ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text: starring jodie foster liam neeson natasha richardson richard libertini nick searcy director michael apted producers renee missel and jodie foster screenplay william nicholson and mark handley based on the play idioglossia by mark handley cinematography dante spinotti music mark isham released by twentieth century fox nell jodie foster return to dramatic acting following flirtation with maverick action comedy is an entirely human movie in this lush green world of rolling hills and crystal pools technology is an unwelcome intruder civilization threatening monster both are slaves to the avaricious nell is about the importance of communication and interaction about how the events of childhood shape life and about the difficulty and rewards of reaching out to others nell foster has lived her entire life alone in the woods with an aging mother she is eventually discovered by local doctor jerome lovell liam neeson who comes to her secluded ramshackle hut on the occasion of her mother death nell panicked and hostile response to strangers forces jerome to travel to nearby charlotte to recruit the expert assistance of dr paula olsen natasha richardson after meeting the young woman paula impression is that nell should be committed jerome horrified by this possibility obtains court order to stop it the two opposing sides eventually argue the case before judge deferring his verdict for three months the judge gives the two doctors that time to observe their subject learn her language and present him with enough evidence to make an informed decision jodie foster two oscars are no fluke as her simple yet profound performance in nell illustrates she is one of only few actors capable of so fully immersing herself in character that it possible to forget the star behind the performance with jack nicholson or al pacino you watch variation of the same personality with jodie foster you see new individual nell is an almost childlike woman who speaks her own fractured form of english hides inside her house by day and takes moonlight swims in nearby lake in jerome and paula she finds substitute father and mother and together these three attempt to breach the non physical walls between them this the real meat of nell is where the film attains its depth and richness at times director michael apted perhaps best known for his documentaries the seven up series incident at oglala seems as enamored with the scenery as with his actors the north carolina terrain is breathtaking and apted along with cinematographer dante spinotti has created one of the most beautiful motion pictures of the year it wonderful background for this tale liam neeson and natasha richardson are solid but constantly in foster shadow in film as frequently introspective as nell it refreshing not to have the three main actors struggling to outdo each other the gentle unforced tone once established is maintained until the unfortunate climax sadly scent of woman disease has infected nell perhaps the writers couldn think of better way out of an admittedly difficult situation but to pander to the hollywood mentality of movie endings is unworthy way to wrap up what is otherwise finely crafted motion picture had the majority of nell not been so impressive the lackluster final act wouldn have been as disappointing despite this moderate tarnish it is difficult to deny nell intelligence and sensitivity we approach this story with the same fascination that nell faces each day seeing if only for short time how different the world and people can be it is this impression more than any other that stays with the viewer after the drama has been played out and the final credits roll the above represents the opinions of the author and not necessarily those of bellcore or any organization within bellcore \n",
            "label: 0.78\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from gensim.utils import simple_preprocess\n",
        "def load_data():\n",
        "    examples, labels = [], []\n",
        "    authors = os.listdir(\"scale_whole_review\")\n",
        "    for author in authors:\n",
        "        path = os.listdir(os.path.join(\"scale_whole_review\", author, \"txt.parag\"))\n",
        "        fn_ids = os.path.join(\"scaledata\", author, \"id.\" + author)\n",
        "        fn_ratings = os.path.join(\"scaledata\", author, \"rating.\" + author)\n",
        "        with open(fn_ids) as ids, open(fn_ratings) as ratings:\n",
        "            for idx, rating in zip(ids, ratings):\n",
        "                labels.append(float(rating.strip()))\n",
        "                filename_text = os.path.join(\"scale_whole_review\", author, \"txt.parag\", idx.strip() + \".txt\")\n",
        "                with open(filename_text, encoding='latin-1') as f:\n",
        "                    examples.append(\" \".join(simple_preprocess(f.read())))\n",
        "    return examples, labels\n",
        "                  \n",
        "X,y  = load_data()\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "print (\"text:\", X_train[0], \"\\nlabel:\", y_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpY4FAyfh00b",
        "outputId": "1f8ce1db-6edf-400c-c889-a7e94e6f2a46"
      },
      "id": "IpY4FAyfh00b",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3354"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "284033cf",
      "metadata": {
        "id": "284033cf"
      },
      "source": [
        "## Vectorize the data"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwfIGXZuiqho",
        "outputId": "418d4ac7-4eec-4f95-94e4-93f2fd64aa1a"
      },
      "id": "DwfIGXZuiqho",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3354, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##TODO vectorize the pre-processed text using TfidfVectorizer\n",
        "##TODO transform X_train to TF-IDF values\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(min_df=0.01, \n",
        "                        max_df=0.9,  \n",
        "                        max_features=1000,\n",
        "                        stop_words='english',\n",
        "                        use_idf=True, # the new piece\n",
        "                        ngram_range=(1,2))\n",
        "\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "\n",
        "##TODO transform X_test to TF-IDF values\n",
        "X_test_tfidf = tfidf.transform(X_test)"
      ],
      "metadata": {
        "id": "MxcshluJj5Uh"
      },
      "id": "MxcshluJj5Uh",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "58d44dbb",
      "metadata": {
        "id": "58d44dbb"
      },
      "outputs": [],
      "source": [
        "##TODO scale both training and test data with the standard scaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler(with_mean=False)\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train_tfidf)\n",
        "X_test_scaled = scaler.transform(X_test_tfidf)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad9d8a57",
      "metadata": {
        "id": "ad9d8a57"
      },
      "source": [
        "## ElasticNet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##TODO train the ElasticNet\n",
        "\n",
        "from sklearn.linear_model import ElasticNet\n",
        "enet_reg = ElasticNet(alpha=.1, l1_ratio=.0001)\n",
        "enet_reg.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "AlrbDnIsryLy",
        "outputId": "2620cbde-acfc-495d-c65a-c287bfa40286"
      },
      "id": "AlrbDnIsryLy",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:592: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11.600957020879818, tolerance: 0.011176031213476434\n",
            "  model = cd_fast.sparse_enet_coordinate_descent(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ElasticNet(alpha=0.1, l1_ratio=0.0001)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ElasticNet(alpha=0.1, l1_ratio=0.0001)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet(alpha=0.1, l1_ratio=0.0001)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1e5f4520",
      "metadata": {
        "id": "1e5f4520",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b208585-9c24-48d4-a8be-60dadfac59b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE:0.019260634645141047\n",
            "r2 score:0.40548886766376624\n"
          ]
        }
      ],
      "source": [
        "##TODO predict the testset\n",
        "y_pred = enet_reg.predict(X_test_scaled)\n",
        "from sklearn.metrics import r2_score, accuracy_score, mean_squared_error, balanced_accuracy_score\n",
        "\n",
        "##TODO print mean squared error and r2 score on the test set\n",
        "print(f\"MSE:{mean_squared_error(y_test, y_pred)}\")\n",
        "print(f\"r2 score:{r2_score(y_test, y_pred)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "872d1ef8",
      "metadata": {
        "id": "872d1ef8"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27e2756e",
      "metadata": {
        "id": "27e2756e"
      },
      "source": [
        "Next, we train an OLS model doing binary prediction on these movie reviews. Two get two bins, we transform the continuous ratings into two classes, where one class contains all the negative ratings (value < 0.5), the other class all the positive ratings (value > 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "9cbd752c",
      "metadata": {
        "id": "9cbd752c"
      },
      "outputs": [],
      "source": [
        "y_train = [1 if i >= 0.5 else 0 for i in y_train]\n",
        "y_test = [1 if i >= 0.5 else 0 for i in y_test]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2c2c239d",
      "metadata": {
        "id": "2c2c239d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e46b2df-2469-4709-ba96-4b5a0735ead4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7378934624697336"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "##TODO train logistic regression on X_train\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logistic_regression = LogisticRegression()\n",
        "\n",
        "##TODO train a logistic regression\n",
        "\n",
        "logistic_regression.fit(X_train_scaled, y_train)\n",
        "##TODO predict the testset \n",
        "y_pred = logistic_regression.predict(X_test_scaled)\n",
        "\n",
        "##since we have continuous output, we need to post-process our labels into two classes. We choose a threshold of 0.5 \n",
        "def map_predictions(predicted):\n",
        "    pred = [1 if i > 0.5 else 0 for i in predicted]\n",
        "    return pred\n",
        "\n",
        "##TODO print the accuracy of our classifier on the testset\n",
        "accuracy_score(y_test, map_predictions(y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning"
      ],
      "metadata": {
        "id": "3hNKx6fUGgCL"
      },
      "id": "3hNKx6fUGgCL"
    },
    {
      "cell_type": "markdown",
      "id": "d0a6bc62",
      "metadata": {
        "id": "d0a6bc62"
      },
      "source": [
        "## MLP"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import the AG news dataset (same as hw01)\n",
        "#Download them from here \n",
        "!wget https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv\n",
        "\n",
        "import pandas as pd\n",
        "import nltk\n",
        "df = pd.read_csv('train.csv')\n",
        "\n",
        "df.columns = [\"label\", \"title\", \"lead\"]\n",
        "label_map = {1:\"world\", 2:\"sport\", 3:\"business\", 4:\"sci/tech\"}\n",
        "def replace_label(x):\n",
        "\treturn label_map[x]\n",
        "df[\"label\"] = df[\"label\"].apply(replace_label) \n",
        "df[\"text\"] = df[\"title\"] + \" \" + df[\"lead\"]\n",
        "df = df.sample(n=10000) # # only use 10K datapoints\n",
        "df.head()"
      ],
      "metadata": {
        "id": "ueplJsWuS_zl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "b60012b0-5893-4f76-b1e3-2f89a71c230d"
      },
      "id": "ueplJsWuS_zl",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-22 13:42:23--  https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29470338 (28M) [text/plain]\n",
            "Saving to: ‘train.csv’\n",
            "\n",
            "train.csv           100%[===================>]  28.10M   174MB/s    in 0.2s    \n",
            "\n",
            "2023-03-22 13:42:24 (174 MB/s) - ‘train.csv’ saved [29470338/29470338]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           label                                              title  \\\n",
              "41249      sport              Weingartner, Washington fall in Seoul   \n",
              "109431     sport     McCarthy #39;s late header sends Porto through   \n",
              "75588      world    Australian Govt. in Control of Both Houses (AP)   \n",
              "905        world  National pharmacare program would reduce hospi...   \n",
              "96220   sci/tech                    EMI's download music sales soar   \n",
              "\n",
              "                                                     lead  \\\n",
              "41249   Seoul, Korea (Sports Network) - Third-seeded G...   \n",
              "109431  DEFENDING champions Porto sneaked through to t...   \n",
              "75588   AP - Final election results Thursday showed Jo...   \n",
              "905     Canadian Press - TORONTO (CP) - A national pha...   \n",
              "96220   EMI sees download music sales rise by nearly 6...   \n",
              "\n",
              "                                                     text  \n",
              "41249   Weingartner, Washington fall in Seoul Seoul, K...  \n",
              "109431  McCarthy #39;s late header sends Porto through...  \n",
              "75588   Australian Govt. in Control of Both Houses (AP...  \n",
              "905     National pharmacare program would reduce hospi...  \n",
              "96220   EMI's download music sales soar EMI sees downl...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-65edca7b-fd16-4ad5-8a01-88c79e28de6c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>title</th>\n",
              "      <th>lead</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>41249</th>\n",
              "      <td>sport</td>\n",
              "      <td>Weingartner, Washington fall in Seoul</td>\n",
              "      <td>Seoul, Korea (Sports Network) - Third-seeded G...</td>\n",
              "      <td>Weingartner, Washington fall in Seoul Seoul, K...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109431</th>\n",
              "      <td>sport</td>\n",
              "      <td>McCarthy #39;s late header sends Porto through</td>\n",
              "      <td>DEFENDING champions Porto sneaked through to t...</td>\n",
              "      <td>McCarthy #39;s late header sends Porto through...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75588</th>\n",
              "      <td>world</td>\n",
              "      <td>Australian Govt. in Control of Both Houses (AP)</td>\n",
              "      <td>AP - Final election results Thursday showed Jo...</td>\n",
              "      <td>Australian Govt. in Control of Both Houses (AP...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>905</th>\n",
              "      <td>world</td>\n",
              "      <td>National pharmacare program would reduce hospi...</td>\n",
              "      <td>Canadian Press - TORONTO (CP) - A national pha...</td>\n",
              "      <td>National pharmacare program would reduce hospi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96220</th>\n",
              "      <td>sci/tech</td>\n",
              "      <td>EMI's download music sales soar</td>\n",
              "      <td>EMI sees download music sales rise by nearly 6...</td>\n",
              "      <td>EMI's download music sales soar EMI sees downl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65edca7b-fd16-4ad5-8a01-88c79e28de6c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-65edca7b-fd16-4ad5-8a01-88c79e28de6c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-65edca7b-fd16-4ad5-8a01-88c79e28de6c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a new variable \"business\" that takes value 1 if the label is business and 0 otherwise\n",
        "df['business'] = df['label'].apply(lambda x: int(x=='business'))\n",
        "y = df['business'].values\n",
        "df['business'].head()"
      ],
      "metadata": {
        "id": "df6ZVZfDTBwH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5c4b0e2-9be8-472e-c64a-e011fd00a44e"
      },
      "id": "df6ZVZfDTBwH",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41249     0\n",
              "109431    0\n",
              "75588     0\n",
              "905       0\n",
              "96220     0\n",
              "Name: business, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# pre-process text as you did in HW02\n",
        "def tokenize(x):\n",
        "    return [w.lemma_.lower() for w in nlp(x) if not w.is_stop and not w.is_punct and not w.is_digit]\n",
        "df[\"tokens\"] = df[\"text\"].apply(lambda x: tokenize(x))\n",
        "df[\"preprocessed\"] = df[\"tokens\"].apply(lambda x: \" \".join(x))\n",
        "\n",
        "##TODO vectorize the pre-processed text using CountVectorizer\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vec = CountVectorizer(min_df=0.01, # at min 1% of docs\n",
        "                        max_df=.9,  \n",
        "                        max_features=1000,\n",
        "                        stop_words='english',\n",
        "                        ngram_range=(1,3))\n",
        "X_count = vec.fit_transform(df['preprocessed'])\n",
        "X_count.shape\n",
        "\n",
        "pd.to_pickle(X_count, 'X.pkl')"
      ],
      "metadata": {
        "id": "1DmdvHAfyUrB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1edcbb01-28f4-480b-c3fc-cc034510f1b1"
      },
      "id": "1DmdvHAfyUrB",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = vec.get_feature_names_out()\n",
        "pd.to_pickle(vocab, 'vocab.pkl')\n",
        "\n",
        "Y = df['business']"
      ],
      "metadata": {
        "id": "WQkSY2yOyGuc"
      },
      "id": "WQkSY2yOyGuc",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9b6e66fc",
      "metadata": {
        "id": "9b6e66fc"
      },
      "source": [
        "Your goal here is to use features from the Vectorized text to predict whether the snippet is from a business article."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "## TODO build a MLP model with at least 2 hidden layers with ReLU activation, followed by dropout and an output layer with sigmoid activation\n",
        "model = Sequential()\n",
        "model.add(Dense(50, # the layer is of type Dense and there are 50 neurons in layer\n",
        "                input_dim=X_count.shape[1], #number of inputs\n",
        "                activation='relu')) # optional activation function\n",
        "\n",
        "# adding more layers\n",
        "# we only need to indicate the input dimension for the first layer, after keras figures it out\n",
        "model.add(Dense(50, activation='relu')) #hidden layer\n",
        "\n",
        "# add the output layer\n",
        "model.add(Dense(1, activation='relu')) #output layer\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "YviQ7DOi2Flb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e170d98f-fb57-4301-b310-85ae086de222"
      },
      "id": "YviQ7DOi2Flb",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 50)                21200     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 50)                2550      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,801\n",
            "Trainable params: 23,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## TODO compile the model\n",
        "model.compile(loss=\"binary_crossentropy\", #specify loss function\n",
        "              optimizer=\"adam\",\n",
        "              metrics=[\"accuracy\"]) "
      ],
      "metadata": {
        "id": "NX9XLpFn2IDo"
      },
      "id": "NX9XLpFn2IDo",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b718ae5",
      "metadata": {
        "id": "0b718ae5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25534c9a-27db-40b5-ed25-51b7748ad241"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "313/313 [==============================] - 2s 3ms/step - loss: 0.5009 - accuracy: 0.8600\n",
            "Epoch 2/4\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3838 - accuracy: 0.9022\n",
            "Epoch 3/4\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3381 - accuracy: 0.9115\n",
            "Epoch 4/4\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3090 - accuracy: 0.9224\n"
          ]
        }
      ],
      "source": [
        "## TODO fit the model using early stopping to predict the business label\n",
        "\n",
        "model_trained = model.fit(X_count.todense(), Y, epochs=4) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6958fddb",
      "metadata": {
        "id": "6958fddb"
      },
      "source": [
        "## Autoencoders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64674cd4",
      "metadata": {
        "id": "64674cd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2828314-7ade-460c-f1ae-7ae02ea38de5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_11 (Dense)            (None, 100)               40900     \n",
            "                                                                 \n",
            " compression_layer (Dense)   (None, 25)                2525      \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 100)               2600      \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 408)               41208     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 87,233\n",
            "Trainable params: 87,233\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "250/250 [==============================] - 3s 7ms/step - loss: 0.0286 - r2: 0.1796 - val_loss: 0.0238 - val_r2: 0.3094\n",
            "Epoch 2/10\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.0223 - r2: 0.3604 - val_loss: 0.0208 - val_r2: 0.3972\n",
            "Epoch 3/10\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.0201 - r2: 0.4229 - val_loss: 0.0196 - val_r2: 0.4334\n",
            "Epoch 4/10\n",
            "250/250 [==============================] - 3s 12ms/step - loss: 0.0192 - r2: 0.4493 - val_loss: 0.0192 - val_r2: 0.4433\n",
            "Epoch 5/10\n",
            "250/250 [==============================] - 2s 9ms/step - loss: 0.0189 - r2: 0.4597 - val_loss: 0.0190 - val_r2: 0.4496\n",
            "Epoch 6/10\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.0186 - r2: 0.4697 - val_loss: 0.0189 - val_r2: 0.4522\n",
            "Epoch 7/10\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0184 - r2: 0.4747 - val_loss: 0.0187 - val_r2: 0.4586\n",
            "Epoch 8/10\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.0182 - r2: 0.4780 - val_loss: 0.0187 - val_r2: 0.4585\n",
            "Epoch 9/10\n",
            "250/250 [==============================] - 3s 10ms/step - loss: 0.0181 - r2: 0.4811 - val_loss: 0.0185 - val_r2: 0.4627\n",
            "Epoch 10/10\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.0180 - r2: 0.4864 - val_loss: 0.0185 - val_r2: 0.4642\n"
          ]
        }
      ],
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def r2(y_true, y_pred):\n",
        "    SS_res =  K.sum(K.square( y_true-y_pred )) \n",
        "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) ) \n",
        "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
        "\n",
        "##TODO build a simple autoencoder with two compression layers and two reconstruction layers using ReLu\n",
        "model = Sequential()\n",
        "model.add(Dense(100,\n",
        "                input_dim=X_count.shape[1],\n",
        "                activation='relu'))\n",
        "model.add(Dense(25, activation='relu', name='compression_layer'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(X_count.shape[1], activation='relu'))\n",
        "\n",
        "model.summary()\n",
        "##TODO compile and fit the model minimizing \"mean_squared_error\"\n",
        "model.compile(loss='mean_squared_error',\n",
        "              optimizer='adam',\n",
        "              metrics=[r2])\n",
        "\n",
        "model_info = model.fit(X_count.todense(), X_count.todense(),\n",
        "                       epochs=10,\n",
        "                       validation_split=.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f767eee",
      "metadata": {
        "id": "6f767eee"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1263d8c1",
      "metadata": {
        "id": "1263d8c1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "c9bf38c8",
        "284033cf",
        "ad9d8a57",
        "872d1ef8"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}