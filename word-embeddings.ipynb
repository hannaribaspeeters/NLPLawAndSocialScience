{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Training word2vec**\n",
        "\n",
        "In this section, we train a word2vec model using gensim. We train the model on text8 (which consists of the first 90M characters of a Wikipedia dump from 2006 and is considered one of the benchmarks for evaluating language models).\n"
      ],
      "metadata": {
        "id": "qFM5H6aDxqP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "api.info(\"text8\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toPr4eKNxwXd",
        "outputId": "4654ded5-212d-4fc2-e166-01026873588e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'num_records': 1701,\n",
              " 'record_format': 'list of str (tokens)',\n",
              " 'file_size': 33182058,\n",
              " 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/text8/__init__.py',\n",
              " 'license': 'not found',\n",
              " 'description': 'First 100,000,000 bytes of plain text from Wikipedia. Used for testing purposes; see wiki-english-* for proper full Wikipedia datasets.',\n",
              " 'checksum': '68799af40b6bda07dfa47a32612e5364',\n",
              " 'file_name': 'text8.gz',\n",
              " 'read_more': ['http://mattmahoney.net/dc/textdata.html'],\n",
              " 'parts': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = api.load(\"text8\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xe2xmn8Dx6gf",
        "outputId": "df6c0e11-8aee-42e3-d766-7adf0cd82b9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 31.6/31.6MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Az6thMug3g5K",
        "outputId": "e7e816ad-ccbd-494d-dfa3-084f91363fb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<text8.Dataset at 0x7fccf8599430>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install LineSentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttsXs7dP5WEu",
        "outputId": "14d04adb-9d44-45c0-d087-eea397c91e7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement LineSentence (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for LineSentence\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ioNl11i6GKr",
        "outputId": "6d8b3cd3-aac5-4a7b-aa3e-39cbb9d80cd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.9/dist-packages (4.3.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from gensim) (1.22.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from gensim) (6.3.0)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from gensim) (1.10.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "import gensim.downloader as api\n",
        "from gensim.utils import simple_preprocess\n",
        "\n",
        "# Load \"text8\" dataset from gensim downloader\n",
        "dataset = api.load(\"text8\")\n",
        "\n",
        "# Initialize Word2Vec model with hyperparameters\n",
        "model = Word2Vec(dataset) # number of worker threads"
      ],
      "metadata": {
        "id": "7vnv_Ciq7fx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Word Similarities**\n",
        "\n",
        "gensim models provide almost all the utility you might want to wish for to perform standard word similarity tasks. They are available in the .wv (wordvectors) attribute of the model, more details could be found here.\n"
      ],
      "metadata": {
        "id": "MVdzuqkNx-IZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.most_similar(\"king\")\n",
        "\n",
        "##TODO find the closest words to king"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGN74K5zx9_G",
        "outputId": "0fecb6a3-4cb9-4e4e-c166-09397f4d3c9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('prince', 0.7440363764762878),\n",
              " ('queen', 0.7238773703575134),\n",
              " ('emperor', 0.7014837265014648),\n",
              " ('throne', 0.6960609555244446),\n",
              " ('kings', 0.6862594485282898),\n",
              " ('vii', 0.6750237345695496),\n",
              " ('aragon', 0.6732887625694275),\n",
              " ('regent', 0.664305567741394),\n",
              " ('sultan', 0.6592472195625305),\n",
              " ('pope', 0.6572885513305664)]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "King is to man as woman is to X\n"
      ],
      "metadata": {
        "id": "UopqFvXCyJqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##TODO find the closest word for the vector \"woman\" + \"king\" - \"man\"\n",
        "model.wv.most_similar(positive=[\"woman\", \"king\"], negative=[\"man\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQmR-XTTyIT0",
        "outputId": "368b3b21-e80e-42c7-a245-f9669595a77d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.6874383687973022),\n",
              " ('prince', 0.6202050447463989),\n",
              " ('throne', 0.6170430779457092),\n",
              " ('princess', 0.6168161034584045),\n",
              " ('sigismund', 0.6153447031974792),\n",
              " ('isabella', 0.6132460832595825),\n",
              " ('empress', 0.6125864386558533),\n",
              " ('son', 0.6124827265739441),\n",
              " ('matilda', 0.6055944561958313),\n",
              " ('elizabeth', 0.5988599061965942)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Evaluate Word Similarities**\n",
        "\n",
        "One common way to evaluate word2vec models are word analogy tasks. Let's check how good our model is on one of those. We consider the WordSim353 benchmark, the task is to determine how similar two words are.\n"
      ],
      "metadata": {
        "id": "BGvTrxL5yNUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://alfonseca.org/pubs/ws353simrel.tar.gz\n",
        "!tar xf ws353simrel.tar.gz\n",
        "\n",
        "path = \"wordsim353_sim_rel/wordsim_similarity_goldstandard.txt\"\n",
        "\n",
        "def load_data(path):\n",
        "    X, y = [], []\n",
        "    with open(path) as f:\n",
        "        for line in f:\n",
        "            line = line.strip().split(\"\\t\")\n",
        "            X.append((line[0], line[1])) # each entry in x contains two words, e.g. X[0] = (tiger, cat)\n",
        "            y.append(float(line[-1])) # each entry in y is the annotation how similar two words are, e.g. Y[0] = 7.35\n",
        "    return X, y\n",
        "\n",
        "X, y = load_data(path)\n",
        "print (X[:3], y[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKfWMX5ZyQlF",
        "outputId": "586a3904-3c59-4cd9-95ec-72bbcd263aa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-23 10:10:04--  http://alfonseca.org/pubs/ws353simrel.tar.gz\n",
            "Resolving alfonseca.org (alfonseca.org)... 162.215.249.67\n",
            "Connecting to alfonseca.org (alfonseca.org)|162.215.249.67|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5460 (5.3K) [application/x-gzip]\n",
            "Saving to: ‘ws353simrel.tar.gz’\n",
            "\n",
            "ws353simrel.tar.gz  100%[===================>]   5.33K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-03-23 10:10:04 (548 MB/s) - ‘ws353simrel.tar.gz’ saved [5460/5460]\n",
            "\n",
            "[('tiger', 'cat'), ('tiger', 'tiger'), ('plane', 'car')] [7.35, 10.0, 5.77]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##TODO compute how similar the pairs in the WordSim353 are according to our model\n",
        "# if a word is not present in our model, we assign similarity 0 for \n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "similarities = []\n",
        "\n",
        "for pair in X:\n",
        "    if pair[0] in list(model.wv.index_to_key) and pair[1] in list(model.wv.index_to_key):\n",
        "        similarities.append(model.wv.similarity(pair[0], pair[1]))\n",
        "    else:\n",
        "        similarities.append(0)\n",
        "\n",
        "similarities_summary = pd.DataFrame(list(zip(X, y, similarities)), columns=['pairs', 'similarities_wordsim', 'similarities_w2v'])\n",
        "similarities_summary.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "b6vWJ3AkyT4d",
        "outputId": "b82cf63c-a265-4a4e-b59a-e68a88e75053"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 pairs  similarities_wordsim  similarities_w2v\n",
              "0         (tiger, cat)                  7.35          0.598704\n",
              "1       (tiger, tiger)                 10.00          1.000000\n",
              "2         (plane, car)                  5.77          0.451379\n",
              "3         (train, car)                  6.31          0.555301\n",
              "4  (television, radio)                  6.77          0.717568"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c2767108-2972-4fa7-b9d5-57fcca9489ec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pairs</th>\n",
              "      <th>similarities_wordsim</th>\n",
              "      <th>similarities_w2v</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(tiger, cat)</td>\n",
              "      <td>7.35</td>\n",
              "      <td>0.598704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(tiger, tiger)</td>\n",
              "      <td>10.00</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(plane, car)</td>\n",
              "      <td>5.77</td>\n",
              "      <td>0.451379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(train, car)</td>\n",
              "      <td>6.31</td>\n",
              "      <td>0.555301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(television, radio)</td>\n",
              "      <td>6.77</td>\n",
              "      <td>0.717568</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c2767108-2972-4fa7-b9d5-57fcca9489ec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c2767108-2972-4fa7-b9d5-57fcca9489ec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c2767108-2972-4fa7-b9d5-57fcca9489ec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import spearmanr\n",
        "\n",
        "spearmanr(y, similarities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0nKTjLlyUdB",
        "outputId": "06140d97-0df9-4ee3-b72c-dc5a7480afeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SignificanceResult(statistic=0.6373903244607537, pvalue=1.5426954517594767e-24)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "D5hIkA76_XXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "en = spacy.load('en_core_web_sm')\n",
        "\n",
        "##TODO compute word similarities in the WordSim353 dataset using spaCy word embeddings\n",
        "##TODO compute spearman's rank correlation between these similarities and the human annotations\n",
        "# Don't worry if results are not too convincing for this experiment\n",
        "\n",
        "sim_spacy = []\n",
        "\n",
        "for pair in X:\n",
        "    sim_spacy.append(model.wv.similarity(en(pair[0]), en(pair[1])))\n",
        "\n",
        "similiarities_summary['spacy'] = sim_spacy\n",
        "\n",
        "similarities_summary.head()\n"
      ],
      "metadata": {
        "id": "OZ0qFbrHyWCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PyTorch Embeddings**"
      ],
      "metadata": {
        "id": "G27l31HiybGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import the AG news dataset (same as hw01)\n",
        "#Download them from here \n",
        "!wget https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv\n",
        "\n",
        "import pandas as pd\n",
        "import nltk\n",
        "df = pd.read_csv('train.csv')\n",
        "\n",
        "df.columns = [\"label\", \"title\", \"lead\"]\n",
        "label_map = {1:\"world\", 2:\"sport\", 3:\"business\", 4:\"sci/tech\"}\n",
        "def replace_label(x):\n",
        "\treturn label_map[x]\n",
        "df[\"label\"] = df[\"label\"].apply(replace_label) \n",
        "df[\"text\"] = df[\"title\"] + \" \" + df[\"lead\"]\n",
        "df = df.sample(n=10000) # # only use 10K datapoints\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "VyeXf4R9yc8Y",
        "outputId": "24b11735-cf5d-4c50-af30-34feb145a6ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-23 10:36:42--  https://raw.githubusercontent.com/mhjabreel/CharCnn_Keras/master/data/ag_news_csv/train.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29470338 (28M) [text/plain]\n",
            "Saving to: ‘train.csv’\n",
            "\n",
            "train.csv           100%[===================>]  28.10M   130MB/s    in 0.2s    \n",
            "\n",
            "2023-03-23 10:36:45 (130 MB/s) - ‘train.csv’ saved [29470338/29470338]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          label                                         title  \\\n",
              "52916  sci/tech      Monti: Courts must rule on MS anti-trust   \n",
              "50946  sci/tech               AT T looks into closing Windows   \n",
              "15836     sport  Citadel Postpones Opener Over Hurricane (AP)   \n",
              "75279     world      Two Moderate Earthquakes Hit Taiwan (AP)   \n",
              "36427  sci/tech                PeopleSoft devotees in denial?   \n",
              "\n",
              "                                                    lead  \\\n",
              "52916  Mario Monti, the outgoing European competition...   \n",
              "50946  A team of researchers is evaluating how Linux ...   \n",
              "15836  AP - The Citadel has postponed its home opener...   \n",
              "75279  AP - Two moderate earthquakes hit eastern Taiw...   \n",
              "36427  With software tycoon Larry Ellison poised to d...   \n",
              "\n",
              "                                                    text  \n",
              "52916  Monti: Courts must rule on MS anti-trust Mario...  \n",
              "50946  AT T looks into closing Windows A team of rese...  \n",
              "15836  Citadel Postpones Opener Over Hurricane (AP) A...  \n",
              "75279  Two Moderate Earthquakes Hit Taiwan (AP) AP - ...  \n",
              "36427  PeopleSoft devotees in denial? With software t...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-faeae88a-7e5a-4017-9602-aea3cbc8bbe9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>title</th>\n",
              "      <th>lead</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>52916</th>\n",
              "      <td>sci/tech</td>\n",
              "      <td>Monti: Courts must rule on MS anti-trust</td>\n",
              "      <td>Mario Monti, the outgoing European competition...</td>\n",
              "      <td>Monti: Courts must rule on MS anti-trust Mario...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50946</th>\n",
              "      <td>sci/tech</td>\n",
              "      <td>AT T looks into closing Windows</td>\n",
              "      <td>A team of researchers is evaluating how Linux ...</td>\n",
              "      <td>AT T looks into closing Windows A team of rese...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15836</th>\n",
              "      <td>sport</td>\n",
              "      <td>Citadel Postpones Opener Over Hurricane (AP)</td>\n",
              "      <td>AP - The Citadel has postponed its home opener...</td>\n",
              "      <td>Citadel Postpones Opener Over Hurricane (AP) A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75279</th>\n",
              "      <td>world</td>\n",
              "      <td>Two Moderate Earthquakes Hit Taiwan (AP)</td>\n",
              "      <td>AP - Two moderate earthquakes hit eastern Taiw...</td>\n",
              "      <td>Two Moderate Earthquakes Hit Taiwan (AP) AP - ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36427</th>\n",
              "      <td>sci/tech</td>\n",
              "      <td>PeopleSoft devotees in denial?</td>\n",
              "      <td>With software tycoon Larry Ellison poised to d...</td>\n",
              "      <td>PeopleSoft devotees in denial? With software t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-faeae88a-7e5a-4017-9602-aea3cbc8bbe9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-faeae88a-7e5a-4017-9602-aea3cbc8bbe9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-faeae88a-7e5a-4017-9602-aea3cbc8bbe9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = 200\n",
        "##TODO tokenize the text, only keep 200 most frequent words \n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# Define the CountVectorizer with the desired hyperparameters\n",
        "vectorizer = CountVectorizer(max_features=200)\n",
        "\n",
        "# Fit the CountVectorizer to the text data in the 'text' column of the DataFrame\n",
        "vectorizer.fit(df['text'])\n",
        "\n",
        "# Transform the 'text' column into a sparse matrix of word counts\n",
        "X = vectorizer.transform(df['text'])\n",
        "\n",
        "# Convert the sparse matrix into a dense matrix for further processing\n",
        "X_dense = X.toarray()\n",
        "\n",
        "print(vectorizer.get_feature_names())"
      ],
      "metadata": {
        "id": "jliCLdJZyeC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n"
      ],
      "metadata": {
        "id": "DfyRWjS2FZS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO create a one_hot representation for each word and truncate/p\n",
        "# Create a one-hot encoder object\n",
        "onehot_encoder = OneHotEncoder()\n",
        "\n",
        "# Fit the one-hot encoder to the CountVectorizer output\n",
        "onehot_encoder.fit(X_dense)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "f274lzJRFT4l",
        "outputId": "679b2195-22d4-4c65-e9e6-1683433b779f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OneHotEncoder()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    }
  ]
}